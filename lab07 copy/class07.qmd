---
title: "lab07"
author: Laurie Chang, A16891192
format: pdf
editor: visual
---

## Clustering Methods

The broad goal here is to find groupings (clusters) in your input data.

## Kmeans

First, let's make up some data to cluster.

```{r}
x <- rnorm(1000)
hist(x)
```
Make a vector of length 60 with 30 points centered at -3 and 30 points centered at +3. 
```{r}
tmp <- c(rnorm(30, mean = -3), rnorm(30, mean = +3))
```

I will now make a wee x and y dataset with 2 groups of points.

```{r}
x <- cbind(x = tmp, y = rev(tmp))
x
plot(x)
```

```{r}
k <- kmeans(x, centers = 2)
k
```

>Q. From your result object `k`, how many points are in each cluster?

```{r}
k$size
```

>Q. What "component" of your result object details the cluster membership?

```{r}
k$cluster
```

>Q. Cluster centers?

```{r}
k$centers
```

>Q. Plot of our clustering results

```{r}
plot(x, col = k$cluster)
points(k$centers, col = "blue", pch = 15, cex = 2)
```

```{r}
# kmeans
m <- kmeans(x, centers = 4)
# plot results
plot(x, col = m$cluster,)
points(m$centers, col = "blue", pch = 15, cex = 2)
```

A big limitation of kmeans is that it does what you ask even if you ask for silly clusters.

## Hierarchial Clustering

The main base R function for Hierarchial Clustering is `hclust()`. Unlike `kmeans()`, you cannot just pass it your data as input. You first need to calulate a distance matrix.

```{r}
d <- dist(x)
hc <- hclust(d)
hc
```

Use `plot()` to view results
```{r}
plot(hc)
abline(h=10, col = "red")
```

To make the "cut" and get our cluster membership vector, we can use the `cutree()` function.

```{r}
grps <- cutree(hc, h = 10)
grps
```

Make a plot of our data colored by hclust results

```{r}
plot(x, col = grps)
```

## Principal Component Analysis (PCA)

Here we will do Principal Component Analysis (PCA) on some food data from the UK.

```{r}
url <- "https://tinyurl.com/UK-foods"
x <- read.csv(url)
```

Rename it so the first column turns into the row name!

*what not to do:
```{r}
rownames(x)
```

what you should do:
```{r}
x <- read.csv(url, row.names = 1)
```


>Q1. How many rows and columns are in your new data frame named x? What R functions could you use to answer this questions?

```{r}
dim(x)
```

preview the first 6 columns
```{r}
head(x)
```

```{r}
x <- read.csv(url, row.names = 1)
head(x)
```

>Q2. Which approach to solving the ‘row-names problem’ mentioned above do you prefer and why? Is one approach more robust than another under certain circumstances?

putting the rownames argument into the `read.csv()` function is a better approach as the other approach, if run many times, can delete data.

```{r}
barplot(as.matrix(x), beside=T, col=rainbow(nrow(x)))
```

>Q3: Changing what optional argument in the above barplot() function results in the following plot?

```{r}
barplot(as.matrix(x), beside=F, col=rainbow(nrow(x)))
```

>Q5: Generating all pairwise plots may help somewhat. Can you make sense of the following code and resulting figure? What does it mean if a given point lies on the diagonal for a given plot?

```{r}
pairs(x, col=rainbow(10), pch=16)
```

This is plotting each country against one another. If a given point lies on the diagnal for the given plot if the points are exactly the same for each country.

>Q6. What is the main differences between N. Ireland and the other countries of the UK in terms of this data-set?

There is a clear difference between N. Ireland and the other countries as there are many dots that are not on the diagonal line (orange, dark blue, etc. are all pretty obviously not on the line).

## PCA to the rescue!

The main "base" R function for PCA is called `prcomp()`.

need to transpose the dataset so the countries are the rows and the food catgeories as the rows

Here we need to take the transpose of our input as we want the countries in the rows and the food in the columns.

```{r}
t(x)
```

```{r}
pca <- prcomp(t(x))
summary(pca)
```

This tells us that PC1 captures 67.44% of variance of the dataset, and so on. PC2 should capture less, etc. If you made a graph of PC1 and PC2, you would captue 96.5% of the spread. We can plot this data with good confidence that we captured the majority of the data. This is how we know our PCA is doing a good job.

>Q. How much variance is captured in 2 PCs?

96.5%

To make our main "PC score plot" (a.k.a. "PC1  vs. PC2 plot",  "PC plot", or "ordination plot").

```{r}
attributes(pca)
```

We are after the `pca$x` result component to make our main PCA plot.

```{r}
pca$x
```

```{r}
mycols <- c("orange", "red", "blue", "darkgreen")
plot(pca$x[,1], pca$x[,2], col = mycols, pch = 16, xlab = "PC1 (67.4%)", ylab = "PC2 (29%)")
```

Another important result is how the original variables (in this case, the foods) contribute to the PCs. 

This is contained in the `pca$rotation` object - folks often call this the "loadings" or "contributions" to the PCs. 

```{r}
pca$rotation
```
This shows numbers of all original categories of all PC columns. The magnitude of the volumes represent the contribution to the PCA.

We can make a plot along PC1.

```{r}
library(ggplot2)

contrib <- as.data.frame(pca$rotation)

ggplot(contrib) +
  aes(PC1, rownames(contrib)) +
  geom_col()
```

The more positive the value, the more Ireland consumes, the more negative the value, the more the other countries consumes.

